{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load image\ndata='/kaggle/input/animal-image-datasetdog-cat-and-panda/animals/'","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom os import listdir","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"listdir(\"/kaggle/input\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"listdir(\"/kaggle/input/animal-image-datasetdog-cat-and-panda\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"listdir(\"/kaggle/input/animal-image-datasetdog-cat-and-panda/animals\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"listdir(\"/kaggle/input/animal-image-datasetdog-cat-and-panda/animals/animals\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"listdir(\"/kaggle/input/animal-image-datasetdog-cat-and-panda/animals/animals/cats\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=[]\ny=[]\n\nk=\"/kaggle/input/animal-image-datasetdog-cat-and-panda/animals/animals/\"\nfor file1 in listdir(k):\n    file2=k+\"/\"+file1\n    for file3 in listdir(file2):\n        file4=file2+\"/\"+file3\n        image = load_img(file4,target_size=(108,108,3))\n        img_array = img_to_array(image)\n        x.append(img_array)\n        y.append(file1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(x),len(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=np.array(x)\ny=np.array(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.shape,y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nk = LabelEncoder()\ny= k.fit_transform(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import to_categorical\ny=to_categorical(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=x/255\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/3, random_state = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Applying VGG16 convolutional neural network","metadata":{}},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=VGG16(input_shape=(108,108,3),include_top=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import Model\nfrom keras.optimizers import SGD\nfrom keras.layers import Flatten, Dense","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Animal_Image():\n    model=VGG16(input_shape=(108,108,3),include_top=False)\n    for layer in model.layers:\n        layer.trainable = False\n    flat1 = Flatten()(model.layers[-1].output)\n    class1 = Dense(128, activation=\"relu\", kernel_initializer=\"he_uniform\")(flat1)\n    class2 = Dense(62, activation=\"relu\", kernel_initializer=\"he_uniform\")(class1)\n    output = Dense(3, activation=\"softmax\")(class1)\n    model1 = Model(inputs=model.inputs, outputs=output)\n    opt = SGD(lr=0.01, momentum=0.9)\n    model1.compile(optimizer=opt,loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    return model1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"obj=Animal_Image()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"objective=obj.fit(x_train,y_train,batch_size=32, validation_data=(x_test,y_test),epochs=12,verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, acc =obj.evaluate(x_test,y_test, verbose=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using ResNet Learning on this dataset","metadata":{}},{"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50\nfrom keras.optimizers import Adam\nfrom keras.layers import Dropout","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define cnn model\ndef define_model():\n    \n    model = ResNet50(include_top=False, input_shape=(108, 108, 3))\n\n    for layer in model.layers:\n        layer.trainable = False\n\n    flat1 = Flatten()(model.layers[-1].output)\n    class1 = Dense(128, activation=\"relu\", kernel_initializer=\"he_uniform\")(flat1)\n    class2 = Dense(62, activation=\"relu\", kernel_initializer=\"he_uniform\")(class1)\n    output = Dense(3, activation=\"softmax\")(class1)\n# define new model\n    model = Model(inputs=model.inputs, outputs=output)\n\n    opt = Adam(lr=0.001)\n    model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k2=define_model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k=k2.fit(x_train,y_train,batch_size=32, validation_data=(x_test,y_test),epochs=12,verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, acc =k2.evaluate(x_test, y_test, verbose=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}